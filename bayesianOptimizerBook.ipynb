{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Libraries\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# Data processing, metrics and modeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold,KFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "# Lgbm\n",
    "import lightgbm as lgb\n",
    "# Suppr warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "from scipy import interp\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "test = load_data('test_prepared.csv')\n",
    "train = load_data('train_prepared.csv')\n",
    "\n",
    "def nan2mean(df):\n",
    "    for x in list(df.columns.values):\n",
    "        df[x] = df[x].fillna(df[x].mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 355/355 [00:31<00:00, 11.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm.tqdm(train.columns): \n",
    "    if train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))  \n",
    "        \n",
    "features = list(train)\n",
    "features.remove('isFraud')\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=nan2mean(train)\n",
    "test=nan2mean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#black box LGBM \n",
    "def LGB_bayesian(\n",
    "    #learning_rate,\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    feature_fraction,\n",
    "    min_child_weight, \n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'feature_fraction' : feature_fraction,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'objective': 'binary',\n",
    "              'save_binary': True,\n",
    "              'seed': 4041,\n",
    "              'feature_fraction_seed': 4041,\n",
    "              'bagging_seed': 4041,\n",
    "              'drop_seed': 4041,\n",
    "              'data_random_seed': 4041,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'verbose': 1,\n",
    "              'is_unbalance': False,\n",
    "              'boost_from_average': True,\n",
    "              'metric':'auc'}    \n",
    "    \n",
    "    oof = np.zeros(len(train))\n",
    "    trn_data= lgb.Dataset(train.iloc[bayesian_tr_idx][features].values, label=train.iloc[bayesian_tr_idx][target].values)\n",
    "    val_data= lgb.Dataset(train.iloc[bayesian_val_idx][features].values, label=train.iloc[bayesian_val_idx][target].values)\n",
    "\n",
    "    clf = lgb.train(param, trn_data,  num_boost_round=50, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds = 50)\n",
    "    \n",
    "    oof[bayesian_val_idx]  = clf.predict(train.iloc[bayesian_val_idx][features].values, num_iteration=clf.best_iteration)  \n",
    "    \n",
    "    score = roc_auc_score(train.iloc[bayesian_val_idx][target].values, oof[bayesian_val_idx])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | min_ch... | min_da... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "|  1        |  0.9358   |  0.377    |  0.9417   |  36.33    |  0.06388  |  94.89    |  104.2    |  1.058    |  1.866    |\n",
      "|  2        |  0.9374   |  0.5991   |  0.7039   |  0.04981  |  0.09729  |  419.6    |  130.6    |  1.182    |  1.183    |\n",
      "|  3        |  0.9299   |  0.3082   |  0.5243   |  21.03    |  0.03621  |  313.7    |  96.42    |  1.292    |  1.366    |\n",
      "|  4        |  0.9161   |  0.4569   |  0.7795   |  9.183    |  0.05628  |  304.4    |  52.79    |  1.608    |  1.171    |\n",
      "|  5        |  0.9275   |  0.07375  |  0.9399   |  48.25    |  0.08276  |  166.2    |  76.81    |  1.684    |  1.44     |\n",
      "|  6        |  0.9506   |  0.1296   |  0.4953   |  0.7538   |  0.09184  |  144.2    |  341.7    |  1.312    |  1.52     |\n",
      "|  7        |  0.9337   |  0.5458   |  0.1912   |  48.45    |  0.07976  |  471.0    |  450.7    |  1.598    |  1.922    |\n",
      "|  8        |  0.8398   |  0.09672  |  0.2021   |  1.307    |  0.03928  |  206.6    |  158.3    |  1.829    |  1.357    |\n",
      "|  9        |  0.9078   |  0.2853   |  0.5418   |  6.187    |  0.0822   |  55.78    |  493.8    |  1.772    |  1.199    |\n",
      "|  10       |  0.9237   |  0.01541  |  0.8092   |  35.05    |  0.07561  |  390.2    |  65.73    |  1.358    |  1.116    |\n",
      "|  11       |  0.9547   |  0.7947   |  0.8763   |  50.0     |  0.01     |  260.3    |  500.0    |  1.0      |  1.801    |\n",
      "|  12       |  0.9215   |  0.3868   |  0.06592  |  44.84    |  0.01301  |  20.47    |  319.0    |  1.154    |  1.296    |\n",
      "|  13       |  0.9092   |  0.13     |  0.3919   |  36.48    |  0.04184  |  23.62    |  34.53    |  1.125    |  1.11     |\n",
      "|  14       |  0.9428   |  0.4624   |  0.4911   |  49.39    |  0.03412  |  493.0    |  246.4    |  1.775    |  1.005    |\n",
      "|  15       |  0.9369   |  0.5345   |  0.656    | -0.5162   |  0.03785  |  423.2    |  132.4    |  1.694    |  1.141    |\n",
      "|  16       |  0.9485   |  0.2114   |  0.6946   | -0.05134  |  0.01337  |  361.4    |  374.3    |  1.387    |  1.937    |\n",
      "|  17       |  0.8766   |  0.5091   |  0.9124   |  3.955    |  0.0533   |  495.1    |  497.8    |  1.909    |  1.308    |\n",
      "|  18       |  0.9365   |  0.3541   |  0.1704   | -0.059    |  0.08211  |  365.5    |  374.8    |  1.079    |  1.545    |\n",
      "|  19       |  0.9482   |  0.7951   |  0.5198   |  49.57    |  0.06425  |  261.1    |  337.5    |  1.574    |  1.921    |\n",
      "|  20       |  0.909    |  0.84     |  0.4783   |  0.7735   |  0.05614  |  499.2    |  35.85    |  1.133    |  1.624    |\n",
      "|  21       |  0.8634   |  0.5278   |  0.4851   |  2.021    |  0.01998  |  147.7    |  340.5    |  1.503    |  1.152    |\n",
      "|  22       |  0.9478   |  0.01     |  0.99     | -1.0      |  0.1      |  20.0     |  203.3    |  1.0      |  2.0      |\n",
      "|  23       |  0.9472   |  0.01     |  0.99     |  50.0     |  0.1      |  353.2    |  250.9    |  2.0      |  2.0      |\n",
      "|  24       |  0.9562   |  0.01     |  0.99     | -1.0      |  0.1      |  45.68    |  389.5    |  1.0      |  2.0      |\n",
      "|  25       |  0.9572   |  0.01     |  0.99     | -1.0      |  0.1      |  164.0    |  500.0    |  1.0      |  2.0      |\n",
      "=========================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.01,\n",
       " 'feature_fraction': 0.99,\n",
       " 'max_depth': -1.0,\n",
       " 'min_child_weight': 0.1,\n",
       " 'min_data_in_leaf': 164.03425015410443,\n",
       " 'num_leaves': 500.0,\n",
       " 'reg_alpha': 1.0,\n",
       " 'reg_lambda': 2.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_tr_idx, bayesian_val_idx = train_test_split(train, test_size = 0.3, random_state = 42, stratify = train[target])\n",
    "bayesian_tr_idx = bayesian_tr_idx.index\n",
    "bayesian_val_idx = bayesian_val_idx.index\n",
    "\n",
    "\n",
    "\n",
    "# Bounded region of parameter space\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (31, 500), \n",
    "    'min_data_in_leaf': (20, 500),\n",
    "    'bagging_fraction' : (0.01, 0.99),\n",
    "    'feature_fraction' : (0.01, 0.99),\n",
    "    'min_child_weight': (0.01, 0.1),   \n",
    "    'reg_alpha': (1, 2), \n",
    "    'reg_lambda': (1, 2),\n",
    "    'max_depth':(-1,50),\n",
    "}\n",
    "\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=42)\n",
    "\n",
    "init_points = 10\n",
    "n_iter = 15\n",
    "\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)\n",
    "\n",
    "\n",
    "LGB_BO.max[\"target\"]\n",
    "\n",
    "\n",
    "\n",
    "LGB_BO.max['params']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
