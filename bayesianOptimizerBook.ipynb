{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Libraries\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# Data processing, metrics and modeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold,KFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "# Lgbm\n",
    "import lightgbm as lgb\n",
    "# Suppr warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "from scipy import interp\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "test = load_data('test_prepared.csv')\n",
    "train = load_data('train_prepared.csv')\n",
    "\n",
    "def nan2mean(df):\n",
    "    for x in list(df.columns.values):\n",
    "        df[x] = df[x].fillna(df[x].mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 355/355 [00:29<00:00, 11.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm.tqdm(train.columns): \n",
    "    if train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))  \n",
    "        \n",
    "features = list(train)\n",
    "features.remove('isFraud')\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=nan2mean(train)\n",
    "test=nan2mean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#black box LGBM \n",
    "def LGB_bayesian(\n",
    "    #learning_rate,\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    feature_fraction,\n",
    "    min_child_weight, \n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'feature_fraction' : feature_fraction,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'objective': 'binary',\n",
    "              'save_binary': True,\n",
    "              'seed': 4041,\n",
    "              'feature_fraction_seed': 4041,\n",
    "              'bagging_seed': 4041,\n",
    "              'drop_seed': 4041,\n",
    "              'data_random_seed': 4041,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'verbose': 1,\n",
    "              'is_unbalance': False,\n",
    "              'boost_from_average': True,\n",
    "              'metric':'auc'}    \n",
    "    \n",
    "    oof = np.zeros(len(train))\n",
    "    trn_data= lgb.Dataset(train.iloc[bayesian_tr_idx][features].values, label=train.iloc[bayesian_tr_idx][target].values)\n",
    "    val_data= lgb.Dataset(train.iloc[bayesian_val_idx][features].values, label=train.iloc[bayesian_val_idx][target].values)\n",
    "\n",
    "    clf = lgb.train(param, trn_data,  num_boost_round=50, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds = 50)\n",
    "    \n",
    "    oof[bayesian_val_idx]  = clf.predict(train.iloc[bayesian_val_idx][features].values, num_iteration=clf.best_iteration)  \n",
    "    \n",
    "    score = roc_auc_score(train.iloc[bayesian_val_idx][target].values, oof[bayesian_val_idx])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | min_ch... | min_da... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "|  1        |  0.9369   |  0.3996   |  0.8606   |  36.33    |  0.06027  |  94.89    |  104.2    |  0.1162   |  1.732    |\n",
      "|  2        |  0.9383   |  0.5809   |  0.6665   |  0.04981  |  0.09702  |  419.6    |  130.6    |  0.3636   |  0.3668   |\n",
      "|  3        |  0.9306   |  0.3434   |  0.5198   |  21.03    |  0.02983  |  313.7    |  96.42    |  0.5843   |  0.7327   |\n",
      "|  4        |  0.9157   |  0.4649   |  0.7281   |  9.183    |  0.05191  |  304.4    |  52.79    |  1.215    |  0.341    |\n",
      "|  5        |  0.9304   |  0.152    |  0.8591   |  48.25    |  0.08103  |  166.2    |  76.81    |  1.368    |  0.8803   |\n",
      "|  6        |  0.9531   |  0.1976   |  0.4961   |  0.7538   |  0.09102  |  144.2    |  341.7    |  0.6234   |  1.04     |\n",
      "|  7        |  0.9399   |  0.5374   |  0.2479   |  48.45    |  0.07774  |  471.0    |  450.7    |  1.196    |  1.844    |\n",
      "|  8        |  0.8437   |  0.1708   |  0.2568   |  1.307    |  0.03321  |  206.6    |  158.3    |  1.657    |  0.7135   |\n",
      "|  9        |  0.9102   |  0.3247   |  0.5342   |  6.187    |  0.08042  |  55.78    |  493.8    |  1.544    |  0.3974   |\n",
      "|  10       |  0.925    |  0.1044   |  0.7524   |  35.05    |  0.07317  |  390.2    |  65.73    |  0.7169   |  0.2317   |\n",
      "|  11       |  0.9562   |  0.9      |  0.9      |  50.0     |  0.1      |  264.5    |  500.0    |  0.0      |  2.0      |\n",
      "|  12       |  0.9437   |  0.4076   |  0.1456   |  44.84    |  0.004309 |  20.47    |  319.0    |  0.308    |  0.5922   |\n",
      "|  13       |  0.8966   |  0.9      |  0.1      | -1.0      |  0.1      |  20.0     |  31.0     |  0.0      |  2.0      |\n",
      "|  14       |  0.9503   |  0.1343   |  0.6331   | -0.8103   |  0.02515  |  378.3    |  384.7    |  0.07409  |  1.788    |\n",
      "|  15       |  0.9498   |  0.2875   |  0.6012   |  46.38    |  0.02692  |  467.9    |  450.6    |  0.3836   |  1.14     |\n",
      "|  16       |  0.9362   |  0.4469   |  0.1648   |  0.1239   |  0.09595  |  487.5    |  499.3    |  0.5361   |  0.9833   |\n",
      "|  17       |  0.9436   |  0.106    |  0.3759   |  48.07    |  0.05095  |  495.8    |  265.6    |  0.6779   |  0.09673  |\n",
      "|  18       |  0.9501   |  0.5113   |  0.3003   |  49.97    |  0.03225  |  131.7    |  417.3    |  0.9758   |  1.427    |\n",
      "|  19       |  0.9513   |  0.2725   |  0.4043   |  0.1153   |  0.06512  |  360.6    |  496.7    |  0.7705   |  0.1719   |\n",
      "|  20       |  0.917    |  0.217    |  0.8842   |  48.09    |  0.06767  |  22.87    |  43.29    |  1.246    |  1.73     |\n",
      "|  21       |  0.9491   |  0.1447   |  0.6796   |  48.09    |  0.06884  |  387.6    |  264.4    |  0.3839   |  0.3932   |\n",
      "|  22       |  0.9438   |  0.2571   |  0.322    | -0.7369   |  0.02682  |  497.7    |  387.5    |  0.1408   |  1.082    |\n",
      "|  23       |  0.9317   |  0.4485   |  0.1355   | -0.03743  |  0.01695  |  20.67    |  209.3    |  1.619    |  1.351    |\n",
      "|  24       |  0.951    |  0.4414   |  0.2514   | -0.7166   |  0.09742  |  189.2    |  449.2    |  0.1579   |  0.6438   |\n",
      "|  25       |  0.9523   |  0.8175   |  0.3886   |  49.85    |  0.07966  |  297.4    |  402.4    |  0.042    |  0.5239   |\n",
      "=========================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.9,\n",
       " 'feature_fraction': 0.9,\n",
       " 'max_depth': 50.0,\n",
       " 'min_child_weight': 0.09999999999449685,\n",
       " 'min_data_in_leaf': 264.51564163645276,\n",
       " 'num_leaves': 500.0,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 2.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_tr_idx, bayesian_val_idx = train_test_split(train, test_size = 0.3, random_state = 42, stratify = train[target])\n",
    "bayesian_tr_idx = bayesian_tr_idx.index\n",
    "bayesian_val_idx = bayesian_val_idx.index\n",
    "\n",
    "\n",
    "\n",
    "# Bounded region of parameter space\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (31, 500), \n",
    "    'min_data_in_leaf': (20, 500),\n",
    "    'bagging_fraction' : (0.1, 0.9),\n",
    "    'feature_fraction' : (0.1, 0.9),\n",
    "    'min_child_weight': (0.001, 0.1),   \n",
    "    'reg_alpha': (0, 2), \n",
    "    'reg_lambda': (0, 2),\n",
    "    'max_depth':(-1,50),\n",
    "}\n",
    "\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=42)\n",
    "\n",
    "init_points = 10\n",
    "n_iter = 15\n",
    "\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)\n",
    "\n",
    "\n",
    "LGB_BO.max[\"target\"]\n",
    "\n",
    "\n",
    "\n",
    "LGB_BO.max['params']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
