{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "import lightgbm as lgb\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import multiprocessing\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['input/test_identity.csv', \n",
    "         'input/test_transaction.csv',\n",
    "         'input/train_identity.csv',\n",
    "         'input/train_transaction.csv',\n",
    "         'input/sample_submission.csv']\n",
    "\n",
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "# with multiprocessing.Pool() as pool:\n",
    "#     test_id, test_tr, train_id, train_tr, sub = pool.map(load_data, files)\n",
    "test_id = load_data('input/test_identity.csv')\n",
    "test_tr = load_data('input/test_transaction.csv')\n",
    "train_id = load_data('input/train_identity.csv')\n",
    "train_tr = load_data('input/train_transaction.csv')\n",
    "sub = load_data('input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train_tr, train_id, on='TransactionID', how='left')\n",
    "test = pd.merge(test_tr, test_id, on='TransactionID', how='left')\n",
    "\n",
    "nameMap = {}\n",
    "for col in test.columns:\n",
    "    if '-' in col:\n",
    "        nameMap[col] = col.replace('-','_')\n",
    "test.rename(columns=nameMap, inplace=True)\n",
    "\n",
    "del test_id, test_tr, train_id, train_tr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id_30'] = train['id_30'].str.replace('Mac OS X', 'MacOSX')\n",
    "train['OS_id_30'] = train['id_30'].str.split(' ', expand=True)[0]\n",
    "train['version_id_30'] = train['id_30'].str.split(' ', expand=True)[1]\n",
    "\n",
    "test['id_30'] = test['id_30'].str.replace('Mac OS X', 'MacOSX')\n",
    "test['OS_id_30'] = test['id_30'].str.split(' ', expand=True)[0]\n",
    "test['version_id_30'] = test['id_30'].str.split(' ', expand=True)[1]\n",
    "\n",
    "def matchregex(x):\n",
    "    x = str(x)\n",
    "    # returnList = []\n",
    "    # extraList = []\n",
    "    # for x in mylist:\n",
    "    if re.match(r'.*chrome.*',x.lower()):\n",
    "        return (\"Chrome\")\n",
    "    elif re.match(r'.*chromium.*',x.lower()):\n",
    "        return (\"Chromium\")\n",
    "    elif re.match(r'.*opera.*',x.lower()):\n",
    "        return (\"Opera\")\n",
    "    elif re.match(r'.*firefox.*',x.lower()):\n",
    "        return (\"Firefox\")\n",
    "    elif re.match(r'.*puffin.*',x.lower()):\n",
    "        return (\"Puffin\")\n",
    "    elif re.match(r'.*safari.*',x.lower()):\n",
    "        return (\"Safari\")\n",
    "    elif re.match(r'.*edge.*',x.lower()):\n",
    "        return (\"IE\")\n",
    "    elif re.match(r'.*ie.*',x.lower()):\n",
    "        return (\"IE\")\n",
    "    elif re.match(r'.*google.*',x.lower()):\n",
    "        return (\"Google\")\n",
    "    elif re.match(r'.*samsung.*',x.lower()):\n",
    "        return (\"Native\")\n",
    "    elif re.match(r'.*android.*',x.lower()):\n",
    "        return (\"Native\")\n",
    "    else:\n",
    "        return (\"Generic\")\n",
    "    \n",
    "def getVersion(mystring):\n",
    "    temp = str(mystring).split(' ')\n",
    "    for x in temp:\n",
    "        try: \n",
    "            myfloat = float(x)\n",
    "            return(myfloat)\n",
    "        except:\n",
    "            continue\n",
    "    return np.nan\n",
    "\n",
    "train['browser']=train['id_31'].apply(matchregex)\n",
    "train['b_version']=train['id_31'].apply(getVersion)\n",
    "train['b_version'] = np.where(train['browser'] == 'Native',np.nan, train['b_version'])\n",
    "train['b_version'] = np.where(train['browser'] == 'Generic',np.nan, train['b_version'])\n",
    "\n",
    "test['browser']=test['id_31'].apply(matchregex)\n",
    "test['b_version']=test['id_31'].apply(getVersion)\n",
    "test['b_version'] = np.where(test['browser'] == 'Native',np.nan, test['b_version'])\n",
    "test['b_version'] = np.where(test['browser'] == 'Generic',np.nan, test['b_version'])\n",
    "\n",
    "def findDeviceInfo(inputString):\n",
    "    if re.match(r'.*sm.*',str(inputString).lower()):\n",
    "        return (\"Samsung\")\n",
    "    elif re.match(r'.*sg.*',str(inputString).lower()):\n",
    "        return (\"Samsung\")\n",
    "    elif re.match(r'.*samsung.*',str(inputString).lower()):\n",
    "        return (\"Samsung\")\n",
    "    elif re.match(r'.*gt.*',str(inputString).lower()):\n",
    "        return (\"Samsung\")\n",
    "    elif re.match(r'.*pixel.*',str(inputString).lower()):\n",
    "        return (\"Google\")\n",
    "    elif re.match(r'.*nexus.*',str(inputString).lower()):\n",
    "        return (\"Google\")\n",
    "    elif re.match(r'.*windows.*',str(inputString).lower()):\n",
    "        return (\"Windows\")\n",
    "    elif re.match(r'.*asus.*',str(inputString).lower()):\n",
    "        return (\"ASUS\")\n",
    "    elif re.match(r'.*lg.*',str(inputString).lower()):\n",
    "        return (\"LG\")\n",
    "    elif re.match(r'.*vs.*',str(inputString).lower()):\n",
    "        return (\"LG\")\n",
    "    elif re.match(r'.*ios.*',str(inputString).lower()):\n",
    "        return (\"Apple\")\n",
    "    elif re.match(r'.*macos.*',str(inputString).lower()):\n",
    "        return (\"Apple\")\n",
    "    elif re.match(r'.*moto.*',str(inputString).lower()):\n",
    "        return (\"Motorola\")\n",
    "    elif re.match(r'.*huawei.*',str(inputString).lower()):\n",
    "        return (\"HUAWEI\")\n",
    "    elif re.match(r'.*ale-.*',str(inputString).lower()):\n",
    "        return (\"HUAWEI\")\n",
    "    elif re.match(r'.*-l.*',str(inputString).lower()):\n",
    "        return (\"HUAWEI\")\n",
    "    elif re.match(r'.*blade.*',str(inputString).lower()):\n",
    "        return (\"BLADE\")\n",
    "    elif re.match(r'.*htc.*',str(inputString).lower()):\n",
    "        return (\"HTC\")\n",
    "    elif re.match(r'.*redmi.*',str(inputString).lower()):\n",
    "        return (\"Redmi\")\n",
    "    elif re.match(r'.*lenovo.*',str(inputString).lower()):\n",
    "        return (\"Lenovo\")\n",
    "    elif re.match(r'.*android.*',str(inputString).lower()):\n",
    "        return (\"Android\")\n",
    "    elif re.match(r'.*e5306.*',str(inputString).lower()):\n",
    "        return (\"SONY\")\n",
    "    elif re.match(r'.*f3213.*',str(inputString).lower()):\n",
    "        return (\"SONY\")\n",
    "    elif re.match(r'.*ilium.*',str(inputString).lower()):\n",
    "        return (\"Ilium\")\n",
    "    elif re.match(r'.*trident.*',str(inputString).lower()):\n",
    "        return (\"Trident\")\n",
    "    elif re.match(r'.*rv:.*',str(inputString).lower()):\n",
    "        return (\"Rv\")\n",
    "    elif re.match(r'.*linux.*',str(inputString).lower()):\n",
    "        return (\"Linux\")\n",
    "    elif re.match(r'.*Hisense.*',str(inputString).lower()):\n",
    "        return (\"Hisense\")\n",
    "    else:\n",
    "        return (\"Others\")\n",
    "\n",
    "train['DeviceInfo'] = train['DeviceInfo'].apply(findDeviceInfo)\n",
    "test['DeviceInfo'] = test['DeviceInfo'].apply(findDeviceInfo)\n",
    "\n",
    "train['TransactionAmt'] = (train['TransactionAmt']*100).astype(int)\n",
    "test['TransactionAmt'] = (test['TransactionAmt']*100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 features are going to be dropped for being useless\n",
      "['V103', 'V28', 'V136', 'V300', 'V114', 'V105', 'V14', 'V115', 'V125', 'V119', 'V295', 'id_07', 'C3', 'V111', 'V132', 'V309', 'V117', 'V121', 'V25', 'id_27', 'V23', 'V77', 'id_21', 'V55', 'V104', 'V297', 'V86', 'V311', 'V98', 'V134', 'V123', 'id_18', 'V133', 'V320', 'V110', 'V116', 'V299', 'id_23', 'V65', 'V24', 'V102', 'V118', 'V122', 'V290', 'id_24', 'V109', 'V66', 'V124', 'id_08', 'V106', 'V284', 'V67', 'V101', 'V293', 'V318', 'V298', 'V120', 'id_26', 'V305', 'V108', 'V26', 'V296', 'V129', 'V286', 'V88', 'V281', 'id_25', 'V316', 'V112', 'dist2', 'V135', 'V27', 'V301', 'V321', 'D7', 'id_22', 'V137', 'V113', 'V107', 'V68', 'V319', 'V89', 'id_30', 'id_31']\n"
     ]
    }
   ],
   "source": [
    "one_value_cols = [col for col in train.columns if train[col].nunique() <= 1]\n",
    "one_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]\n",
    "\n",
    "many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]\n",
    "\n",
    "big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "big_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "\n",
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols + one_value_cols_test))\n",
    "cols_to_drop.remove('isFraud')\n",
    "cols_to_drop.extend(['id_30','id_31'])\n",
    "print('{} features are going to be dropped for being useless'.format(len(cols_to_drop)))\n",
    "print(cols_to_drop)\n",
    "\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)\n",
    "\n",
    "train.to_csv(\"train_prepared.csv\")\n",
    "test.to_csv(\"test_prepared.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 354/354 [00:22<00:00, 15.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm.tqdm(train.columns): \n",
    "    if train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 428.58 Mb (73.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']\n",
    "\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV does not support NaNs\n",
    "X.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 500,\n",
    "          'min_child_weight': 0.1,\n",
    "          'feature_fraction': 0.99,\n",
    "          'bagging_fraction': 0.01,\n",
    "          'min_data_in_leaf': 165,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.1,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 4041,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 1.,\n",
    "          'reg_lambda': 2.0,\n",
    "          'random_state': 4041\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(**params)\n",
    "rfe = RFECV(estimator=clf, step=10, cv=KFold(n_splits=5, shuffle=False), scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 341 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 321 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 151 features.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7b519e5c0e77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    520\u001b[0m         scores = parallel(\n\u001b[0;32m    521\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    520\u001b[0m         scores = parallel(\n\u001b[0;32m    521\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[1;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     return rfe._fit(\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    806\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\python\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal number of features:', rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score\")\n",
    "plt.plot(range(1, len(rfe.grid_scores_) + 1), rfe.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list =[]\n",
    "for col in X.columns[rfe.ranking_ == 1]:\n",
    "    print(col)\n",
    "    list.append(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
