{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "import lightgbm as lgb\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import multiprocessing\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['input/test_identity.csv', \n",
    "         'input/test_transaction.csv',\n",
    "         'input/train_identity.csv',\n",
    "         'input/train_transaction.csv',\n",
    "         'input/sample_submission.csv']\n",
    "\n",
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "# with multiprocessing.Pool() as pool:\n",
    "#     test_id, test_tr, train_id, train_tr, sub = pool.map(load_data, files)\n",
    "test_id = load_data('input/test_identity.csv')\n",
    "test_tr = load_data('input/test_transaction.csv')\n",
    "train_id = load_data('input/train_identity.csv')\n",
    "train_tr = load_data('input/train_transaction.csv')\n",
    "sub = load_data('input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 features are going to be dropped for being useless\n",
      "['V122', 'V284', 'V117', 'V77', 'V26', 'V298', 'V119', 'V299', 'V305', 'V290', 'id_27', 'V134', 'V107', 'dist2', 'V295', 'id_26', 'V300', 'V135', 'V104', 'V297', 'V28', 'V105', 'V24', 'V113', 'id_07', 'V65', 'V133', 'V136', 'C3', 'V116', 'V132', 'V320', 'V286', 'V102', 'V112', 'V27', 'V137', 'V23', 'V309', 'V123', 'id_21', 'id_24', 'V120', 'V114', 'V296', 'V88', 'V98', 'V319', 'V121', 'V55', 'V109', 'V110', 'V14', 'V25', 'V311', 'id_08', 'V125', 'id_25', 'V66', 'V293', 'V68', 'V103', 'V118', 'id_23', 'V321', 'V67', 'V129', 'V108', 'V115', 'V124', 'V101', 'id_22', 'V281', 'V316', 'V106', 'id_18', 'V111', 'V86', 'V318', 'V301', 'V89', 'D7']\n"
     ]
    }
   ],
   "source": [
    "train = pd.merge(train_tr, train_id, on='TransactionID', how='left')\n",
    "test = pd.merge(test_tr, test_id, on='TransactionID', how='left')\n",
    "\n",
    "nameMap = {}\n",
    "for col in test.columns:\n",
    "    if '-' in col:\n",
    "        nameMap[col] = col.replace('-','_')\n",
    "test.rename(columns=nameMap, inplace=True)\n",
    "\n",
    "del test_id, test_tr, train_id, train_tr\n",
    "gc.collect()\n",
    "\n",
    "one_value_cols = [col for col in train.columns if train[col].nunique() <= 1]\n",
    "one_value_cols_test = [col for col in test.columns if test[col].nunique() <= 1]\n",
    "\n",
    "many_null_cols = [col for col in train.columns if train[col].isnull().sum() / train.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in test.columns if test[col].isnull().sum() / test.shape[0] > 0.9]\n",
    "\n",
    "big_top_value_cols = [col for col in train.columns if train[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "big_top_value_cols_test = [col for col in test.columns if test[col].value_counts(dropna=False, normalize=True).values[0] > 0.9]\n",
    "\n",
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test + big_top_value_cols + big_top_value_cols_test + one_value_cols + one_value_cols_test))\n",
    "cols_to_drop.remove('isFraud')\n",
    "print('{} features are going to be dropped for being useless'.format(len(cols_to_drop)))\n",
    "print(cols_to_drop)\n",
    "\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 352/352 [00:22<00:00, 15.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm.tqdm(train.columns): \n",
    "    if train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 426.33 Mb (73.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT', 'TransactionID'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']\n",
    "\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFECV does not support NaNs\n",
    "X.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(**params)\n",
    "rfe = RFECV(estimator=clf, step=10, cv=KFold(n_splits=5, shuffle=False), scoring='roc_auc', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 349 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 329 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 309 features.\n"
     ]
    }
   ],
   "source": [
    "rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal number of features:', rfe.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score\")\n",
    "plt.plot(range(1, len(rfe.grid_scores_) + 1), rfe.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns[rfe.ranking_ == 1]:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
