{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Libraries\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# Data processing, metrics and modeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold,KFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, roc_auc_score, f1_score, roc_curve, auc,precision_recall_curve\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "# Lgbm\n",
    "import lightgbm as lgb\n",
    "# Suppr warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "from scipy import interp\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "test = load_data('test_prepared.csv')\n",
    "train = load_data('train_prepared.csv')\n",
    "\n",
    "def nan2mean(df):\n",
    "    for x in list(df.columns.values):\n",
    "        df[x] = df[x].fillna(df[x].mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 355/355 [00:30<00:00, 11.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm.tqdm(train.columns): \n",
    "    if train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))  \n",
    "        \n",
    "features = list(train)\n",
    "features.remove('isFraud')\n",
    "target = 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=nan2mean(train)\n",
    "test=nan2mean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#black box LGBM \n",
    "def LGB_bayesian(\n",
    "    #learning_rate,\n",
    "    num_leaves, \n",
    "    bagging_fraction,\n",
    "    feature_fraction,\n",
    "    min_child_weight, \n",
    "    min_data_in_leaf,\n",
    "    max_depth,\n",
    "    reg_alpha,\n",
    "    reg_lambda\n",
    "     ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. \n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "    \n",
    "\n",
    "    param = {\n",
    "              'num_leaves': num_leaves, \n",
    "              'min_data_in_leaf': min_data_in_leaf,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'bagging_fraction' : bagging_fraction,\n",
    "              'feature_fraction' : feature_fraction,\n",
    "              'max_depth': max_depth,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'objective': 'binary',\n",
    "              'save_binary': True,\n",
    "              'seed': 4041,\n",
    "              'feature_fraction_seed': 4041,\n",
    "              'bagging_seed': 4041,\n",
    "              'drop_seed': 4041,\n",
    "              'data_random_seed': 4041,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'verbose': 1,\n",
    "              'is_unbalance': False,\n",
    "              'boost_from_average': True,\n",
    "              'metric':'auc'}    \n",
    "    \n",
    "    oof = np.zeros(len(train))\n",
    "    trn_data= lgb.Dataset(train.iloc[bayesian_tr_idx][features].values, label=train.iloc[bayesian_tr_idx][target].values)\n",
    "    val_data= lgb.Dataset(train.iloc[bayesian_val_idx][features].values, label=train.iloc[bayesian_val_idx][target].values)\n",
    "\n",
    "    clf = lgb.train(param, trn_data,  num_boost_round=50, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds = 50)\n",
    "    \n",
    "    oof[bayesian_val_idx]  = clf.predict(train.iloc[bayesian_val_idx][features].values, num_iteration=clf.best_iteration)  \n",
    "    \n",
    "    score = roc_auc_score(train.iloc[bayesian_val_idx][target].values, oof[bayesian_val_idx])\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | baggin... | featur... | max_depth | min_ch... | min_da... | num_le... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "|  1        |  0.9458   |  0.3996   |  0.8606   |  36.33    |  0.005991 |  94.89    |  182.2    |  1.058    |  1.866    |\n",
      "|  2        |  0.9455   |  0.5809   |  0.6665   |  0.04981  |  0.009699 |  419.6    |  236.8    |  1.182    |  1.183    |\n",
      "|  3        |  0.9392   |  0.3434   |  0.5198   |  21.03    |  0.002919 |  313.7    |  166.2    |  1.292    |  1.366    |\n",
      "|  4        |  0.9215   |  0.4649   |  0.7281   |  9.183    |  0.005147 |  304.4    |  76.01    |  1.608    |  1.171    |\n",
      "|  5        |  0.939    |  0.152    |  0.8591   |  48.25    |  0.008086 |  166.2    |  125.6    |  1.684    |  1.44     |\n",
      "|  6        |  0.9566   |  0.1976   |  0.4961   |  0.7538   |  0.009094 |  144.2    |  673.0    |  1.312    |  1.52     |\n",
      "|  7        |  0.9384   |  0.5374   |  0.2479   |  48.45    |  0.007754 |  471.0    |  898.1    |  1.598    |  1.922    |\n",
      "|  8        |  0.8437   |  0.1708   |  0.2568   |  1.307    |  0.00326  |  206.6    |  293.9    |  1.829    |  1.357    |\n",
      "|  9        |  0.9082   |  0.3247   |  0.5342   |  6.187    |  0.008024 |  55.78    |  987.3    |  1.772    |  1.199    |\n",
      "|  10       |  0.9331   |  0.1044   |  0.7524   |  35.05    |  0.007293 |  390.2    |  102.7    |  1.358    |  1.116    |\n",
      "|  11       |  0.9269   |  0.1      |  0.1      |  50.0     |  1e-05    |  500.0    |  596.2    |  1.0      |  1.0      |\n",
      "|  12       |  0.9603   |  0.4142   |  0.8218   |  44.79    |  0.007137 |  20.4     |  692.6    |  1.094    |  1.036    |\n",
      "|  13       |  0.9156   |  0.3534   |  0.8145   |  15.51    |  0.006438 |  20.7     |  43.42    |  1.262    |  1.779    |\n",
      "|  14       |  0.9362   |  0.6935   |  0.1279   |  47.83    |  0.004069 |  224.7    |  841.4    |  1.42     |  1.162    |\n",
      "|  15       |  0.9527   |  0.7293   |  0.245    |  49.65    |  0.006272 |  21.74    |  693.5    |  1.357    |  1.725    |\n",
      "|  16       |  0.9328   |  0.4469   |  0.1648   |  0.1239   |  0.009591 |  487.5    |  998.6    |  1.268    |  1.492    |\n",
      "|  17       |  0.8419   |  0.8933   |  0.7915   |  1.269    |  0.008937 |  499.5    |  739.7    |  1.698    |  1.735    |\n",
      "|  18       |  0.9301   |  0.8807   |  0.6128   |  36.14    |  0.001322 |  385.0    |  99.74    |  1.486    |  1.77     |\n",
      "|  19       |  0.8401   |  0.4023   |  0.1196   |  1.32     |  0.000283 |  20.62    |  517.7    |  1.878    |  1.846    |\n",
      "|  20       |  0.876    |  0.5357   |  0.5129   |  3.988    |  0.002045 |  25.04    |  808.3    |  1.237    |  1.387    |\n",
      "|  21       |  0.8634   |  0.5227   |  0.4879   |  2.021    |  0.001117 |  147.7    |  670.5    |  1.503    |  1.152    |\n",
      "|  22       |  0.9351   |  0.6372   |  0.1802   |  19.08    |  0.006633 |  393.4    |  587.0    |  1.245    |  1.947    |\n",
      "|  23       |  0.9485   |  0.1      |  0.9      | -1.0      |  0.01     |  500.0    |  415.2    |  1.0      |  2.0      |\n",
      "|  24       |  0.9439   |  0.729    |  0.2098   |  46.7     |  0.00322  |  306.8    |  936.5    |  1.226    |  1.023    |\n",
      "|  25       |  0.8963   |  0.9      |  0.1      | -1.0      |  0.01     |  500.0    |  31.0     |  2.0      |  2.0      |\n",
      "=========================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.41422760229748556,\n",
       " 'feature_fraction': 0.8218187289758005,\n",
       " 'max_depth': 44.79479909781755,\n",
       " 'min_child_weight': 0.007137471537956045,\n",
       " 'min_data_in_leaf': 20.40495444899225,\n",
       " 'num_leaves': 692.601648892417,\n",
       " 'reg_alpha': 1.0943860705736115,\n",
       " 'reg_lambda': 1.0361212520439498}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesian_tr_idx, bayesian_val_idx = train_test_split(train, test_size = 0.3, random_state = 42, stratify = train[target])\n",
    "bayesian_tr_idx = bayesian_tr_idx.index\n",
    "bayesian_val_idx = bayesian_val_idx.index\n",
    "\n",
    "\n",
    "\n",
    "# Bounded region of parameter space\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (31, 500), \n",
    "    'min_data_in_leaf': (20, 500),\n",
    "    'bagging_fraction' : (0.01, 0.99),\n",
    "    'feature_fraction' : (0.01, 0.99),\n",
    "    'min_child_weight': (0.01, 0.1),   \n",
    "    'reg_alpha': (1, 2), \n",
    "    'reg_lambda': (1, 2),\n",
    "    'max_depth':(-1,50),\n",
    "}\n",
    "\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=42)\n",
    "\n",
    "init_points = 10\n",
    "n_iter = 15\n",
    "\n",
    "print('-' * 130)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)\n",
    "\n",
    "\n",
    "LGB_BO.max[\"target\"]\n",
    "\n",
    "\n",
    "\n",
    "LGB_BO.max['params']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
